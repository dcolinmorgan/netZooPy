{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "panda_aux_dict tests.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9VaaSF3AxN9d90ZEG+l1d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcolinmorgan/netZooPy/blob/master/panda_aux_dict_tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8Tg9IvRAdz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "# from .timer import Timer\n",
        "import numpy as np\n",
        "\n",
        "class Panda(object):\n",
        "    \"\"\" \n",
        "    Description:\n",
        "       Using PANDA to infer gene regulatory network.\n",
        "\n",
        "    Usage:\n",
        "        1. Reading in input data (expression data, motif prior, TF PPI data)\n",
        "        2. Computing coexpression network\n",
        "        3. Normalizing networks\n",
        "        4. Running PANDA algorithm\n",
        "        5. Writing out PANDA network\n",
        "\n",
        "    Inputs:\n",
        "        motif_data: path to file containing the transcription factor DNA binding motif data in the form of TF-gene-weight(0/1).\n",
        "                    if set to none, the gene coexpression matrix is returned as a result network.\n",
        "        save_memory: True : removes temporary results from memory. The result network is weighted adjacency matrix of size (nTFs, nGenes).\n",
        "                     False: keeps the temporary files in memory. The result network has 4 columns in the form gene - TF - weight in motif prior - PANDA edge.\n",
        "        keep_expression_matrix: keeps the input expression matrix in the result Panda object.\n",
        "        modeProcess: The input data processing mode.\n",
        "                    'legacy': refers to the processing mode in netZooPy<=0.5\n",
        "                    (Default)'union': takes the union of all TFs and genes across priors and fills the missing genes in the priors with zeros.\n",
        "                    'intersection': intersects the input genes and TFs across priors and removes the missing TFs/genes.\n",
        "        remove_missing: removes the gens and TFs that are not present in one of the priors. Works only if modeProcess='legacy'\n",
        "        computing  : 'cpu' uses Central Processing Unit (CPU) to run PANDA\n",
        "                     'gpu' use the Graphical Processing Unit (GPU) to run PANDA\n",
        "        precision  : 'double' computes the regulatory network in double precision (15 decimal digits)\n",
        "                     'single' computes the regulatory network in single precision (7 decimal digits) which is fastaer, requires half the memory but less accurate.\n",
        "                      \n",
        "     Methods:\n",
        "        return_panda_indegree: computes indegree of panda network, only if save_memory = False\n",
        "        return_panda_outdegree: computes outdegree of panda network, only if save_memory = False\n",
        "\n",
        "    Outputs:\n",
        "\n",
        "     Authors: \n",
        "       cychen, davidvi, alessandromarin, Marouen Ben Guebila, Daniel Morgan\n",
        "    \"\"\"\n",
        "    def __init__(self, expression_file, motif_file, ppi_file, computing='cpu',precision='double',save_memory = False, save_tmp=True, remove_missing=False, keep_expression_matrix = False, modeProcess = 'union'):\n",
        "        \n",
        "        # Read data\n",
        "        self.processData(modeProcess, motif_file, expression_file, ppi_file, remove_missing, keep_expression_matrix)\n",
        "        if hasattr(self, 'export_panda_results'):\n",
        "            return\n",
        "        \n",
        "        # =====================================================================\n",
        "        # Network normalization\n",
        "        # =====================================================================\n",
        "\n",
        "        with Timer('Normalizing networks ...'):\n",
        "            self.correlation_matrix = self._normalize_network(self.correlation_matrix)\n",
        "            with np.errstate(invalid='ignore'): #silly warning bothering people\n",
        "                self.motif_matrix = self._normalize_network(self.motif_matrix_unnormalized)\n",
        "            self.ppi_matrix = self._normalize_network(self.ppi_matrix)\n",
        "            if precision=='single':\n",
        "                self.correlation_matrix=np.float32(self.correlation_matrix)\n",
        "                self.motif_matrix=np.float32(self.motif_matrix)\n",
        "                self.ppi_matrix=np.float32(self.ppi_matrix)\n",
        "        # =====================================================================\n",
        "        # Clean up useless variables to release memory\n",
        "        # =====================================================================\n",
        "        if save_memory:\n",
        "            print(\"Clearing motif and ppi data, unique tfs, and gene names for speed\")\n",
        "            del self.unique_tfs, self.gene_names, self.motif_matrix_unnormalized\n",
        "\n",
        "        # =====================================================================\n",
        "        # Saving middle data to tmp\n",
        "        # =====================================================================\n",
        "        if save_tmp:\n",
        "            with Timer('Saving expression matrix and normalized networks ...'):\n",
        "                if self.expression_data is not None:\n",
        "                    np.save('/tmp/expression.npy', self.expression_data.values)\n",
        "                np.save('/tmp/motif.normalized.npy', self.motif_matrix)\n",
        "                np.save('/tmp/ppi.normalized.npy', self.ppi_matrix)\n",
        "\n",
        "        # delete expression data\n",
        "        del self.expression_data\n",
        "\n",
        "        # =====================================================================\n",
        "        # Running PANDA algorithm\n",
        "        # =====================================================================\n",
        "        if self.motif_data is not None:\n",
        "            print('Running PANDA algorithm ...')\n",
        "            self.panda_network = self.panda_loop(self.correlation_matrix, self.motif_matrix, self.ppi_matrix,computing)\n",
        "        else:\n",
        "            self.panda_network = self.correlation_matrix\n",
        "            self.__pearson_results_data_frame()\n",
        "\n",
        "\n",
        "    def __remove_missing(self):\n",
        "        '''Remove genes and tfs not present in all files.'''\n",
        "        if self.expression_data is not None:\n",
        "            print(\"Remove expression not in motif:\")\n",
        "            motif_unique_genes = set(self.motif_data[1])\n",
        "            len_tot = len(self.expression_data)\n",
        "            self.expression_data = self.expression_data[self.expression_data.index.isin(motif_unique_genes)]\n",
        "            self.gene_names = self.expression_data.index.tolist()\n",
        "            self.num_genes = len(self.gene_names)\n",
        "            print(\"   {} rows removed from the initial {}\".format(len_tot-self.num_genes,len_tot))\n",
        "        #if self.motif_data is not None:\n",
        "        print(\"Remove motif not in expression data:\")\n",
        "        len_tot = len(self.motif_data)\n",
        "        self.motif_data = self.motif_data[self.motif_data.iloc[:,1].isin(self.gene_names)]\n",
        "        self.unique_tfs = sorted(set(self.motif_data[0]))\n",
        "        self.num_tfs = len(self.unique_tfs)\n",
        "        print(\"   {} rows removed from the initial {}\".format(len_tot-len(self.motif_data),len_tot))\n",
        "        if self.ppi_data is not None:\n",
        "            print(\"Remove ppi not in motif:\")\n",
        "            motif_unique_tfs = np.unique(self.motif_data.iloc[:,0])\n",
        "            len_tot = len(self.ppi_data)\n",
        "            self.ppi_data = self.ppi_data[self.ppi_data.iloc[:,0].isin(motif_unique_tfs)]\n",
        "            self.ppi_data = self.ppi_data[self.ppi_data.iloc[:,1].isin(motif_unique_tfs)]\n",
        "            print(\"   {} rows removed from the initial {}\".format(len_tot-len(self.ppi_data),len_tot))\n",
        "        return None\n",
        "\n",
        "    def _normalize_network(self, x):\n",
        "        norm_col = zscore(x, axis=0)\n",
        "        if x.shape[0] == x.shape[1]:\n",
        "            norm_row = norm_col.T\n",
        "        else:\n",
        "            norm_row = zscore(x, axis=1)\n",
        "        #Alessandro: replace nan values\n",
        "        normalized_matrix = (norm_col + norm_row) / math.sqrt(2)\n",
        "        norm_total = (x-np.mean(x))/np.std(x)   #NB zscore(x) is not the same\n",
        "        nan_col = np.isnan(norm_col)\n",
        "        nan_row = np.isnan(norm_row)\n",
        "        normalized_matrix[nan_col] = (norm_row[nan_col] + norm_total[nan_col])/math.sqrt(2)\n",
        "        normalized_matrix[nan_row] = (norm_col[nan_row] + norm_total[nan_row])/math.sqrt(2)\n",
        "        normalized_matrix[nan_col & nan_row] = 2*norm_total[nan_col & nan_row]/math.sqrt(2)\n",
        "        return normalized_matrix\n",
        "\n",
        "    def processData(self, modeProcess, motif_file, expression_file, ppi_file, remove_missing, keep_expression_matrix):\n",
        "        # if modeProcess==\"legacy\":\n",
        "        # =====================================================================\n",
        "        # Data loading\n",
        "        # =====================================================================\n",
        "        if type(motif_file) is str:\n",
        "            with Timer('Loading motif data ...'):\n",
        "                self.motif_data = pd.read_csv(motif_file, sep='\\t', header=None)\n",
        "                self.motif_tfs = sorted(set(self.motif_data[0]))\n",
        "                self.motif_genes = sorted(set(self.motif_data[1]))\n",
        "                # self.num_tfs = len(self.unique_tfs)\n",
        "                # print('Unique TFs:', self.num_tfs)\n",
        "        elif type(motif_file) is not str:\n",
        "            self.motif_data = pd.DataFrame(motif_file.values)#pd.read_csv(motif_file, sep='\\t', header=None)\n",
        "            self.motif_tfs = sorted(set(motif_file['source']))\n",
        "            self.motif_genes = sorted(set(motif_file['target']))\n",
        "            # self.num_tfs = len(self.unique_tfs)\n",
        "            # print('Unique TFs:', self.num_tfs)\n",
        "\n",
        "        else:\n",
        "            self.motif_data = None\n",
        "\n",
        "        if type(expression_file) is str:\n",
        "            with Timer('Loading expression data ...'):\n",
        "                self.expression_data = pd.read_csv(expression_file, sep='\\t', header=None, index_col=0)\n",
        "                self.expression_genes = self.expression_data.index.tolist()\n",
        "                # self.num_genes = len(self.gene_names)\n",
        "                # print('Expression matrix:', self.expression_data.shape)\n",
        "        elif type(expression_file) is not str:\n",
        "            self.expression_data = expression_file #pd.read_csv(expression_file, sep='\\t', header=None, index_col=0)\n",
        "            self.expression_genes = self.expression_data.index.tolist()\n",
        "            # self.num_genes = len(self.gene_names)\n",
        "            # print('Expression matrix:', self.expression_data.shape)\n",
        "        else:\n",
        "            self.gene_names = list(set(self.motif_data[1]))\n",
        "            self.num_genes = len(self.gene_names)\n",
        "            self.expression_data = None #pd.DataFrame(np.identity(self.num_genes, dtype=int))\n",
        "            print('No Expression data given: correlation matrix will be an identity matrix of size', self.num_genes)\n",
        "\n",
        "        if type(ppi_file) is str:\n",
        "            with Timer('Loading PPI data ...'):\n",
        "                self.ppi_data = pd.read_csv(ppi_file, sep='\\t', header=None)\n",
        "                self.ppi_tfs  = sorted(set(self.ppi_data[0]))\n",
        "                print('Number of PPIs:', self.ppi_data.shape[0])\n",
        "        elif type(ppi_file) is not str:\n",
        "            self.ppi_data = ppi_file#pd.read_csv(ppi_file, sep='\\t', header=None)\n",
        "            self.ppi_tfs  = sorted(set(self.ppi_data[0]))\n",
        "            print('Number of PPIs:', self.ppi_data.shape[0])\n",
        "        else:\n",
        "            print('No PPI data given: ppi matrix will be an identity matrix of size', self.num_tfs)\n",
        "            self.ppi_data = None\n",
        "\n",
        "        if remove_missing and motif_file is not None:\n",
        "            self.__remove_missing()\n",
        "        \n",
        "        if modeProcess==\"legacy\":\n",
        "            self.gene_names = self.expression_genes#sorted( np.unique(self.motif_genes +  self.expression_genes ))\n",
        "            self.unique_tfs = self.motif_tfs#sorted( np.unique(self.ppi_tfs     +  self.motif_tfs ))\n",
        "\n",
        "        elif modeProcess==\"union\":\n",
        "            self.gene_names = sorted( np.unique(self.motif_genes +  self.expression_genes ))\n",
        "            self.unique_tfs = sorted( np.unique(self.ppi_tfs     +  self.motif_tfs ))\n",
        "\n",
        "        elif modeProcess==\"intersection\":\n",
        "            self.gene_names = sorted(np.unique( list(set(self.motif_genes).intersection(set(self.expression_genes))) ))\n",
        "            self.unique_tfs = sorted(np.unique( list(set(self.ppi_tfs).intersection(set(self.motif_tfs)) )))\n",
        "        \n",
        "        self.num_genes  = len(self.gene_names)\n",
        "        self.num_tfs    = len(self.unique_tfs)\n",
        "\n",
        "        # Auxiliary dicts\n",
        "        gene2idx = {x: i for i,x in enumerate(self.gene_names)}\n",
        "        tf2idx = {x: i for i,x in enumerate(self.unique_tfs)}\n",
        "        if modeProcess==\"union\" or modeProcess==\"intersection\":\n",
        "            # Initialize data & Populate gene expression\n",
        "            self.expression = np.zeros((self.num_genes, self.expression_data.shape[1]))\n",
        "            print(self.expression.shape)\n",
        "            print(self.expression_data.shape)\n",
        "            if modeProcess==\"union\":\n",
        "                idx_geneEx = [gene2idx.get(x, 0) for x in self.expression_genes]\n",
        "            else:\n",
        "                idx_geneEx = [gene2idx.get(x, 0) for x in self.gene_names]\n",
        "            self.expression[idx_geneEx,:] = self.expression_data.values\n",
        "            self.expression_data=pd.DataFrame(data=self.expression)\n",
        "\n",
        "        # =====================================================================\n",
        "        # Network construction\n",
        "        # =====================================================================\n",
        "        with Timer('Calculating coexpression network ...'):\n",
        "            if self.expression_data is None:\n",
        "                self.correlation_matrix = np.identity(self.num_genes,dtype=int)\n",
        "            else:\n",
        "                self.correlation_matrix = np.corrcoef(self.expression_data)\n",
        "            if np.isnan(self.correlation_matrix).any():\n",
        "                np.fill_diagonal(self.correlation_matrix, 1)\n",
        "                self.correlation_matrix = np.nan_to_num(self.correlation_matrix)\n",
        "\n",
        "        # Clean up useless variables to release memory\n",
        "        if keep_expression_matrix:\n",
        "            self.expression_matrix = self.expression_data.values\n",
        "\n",
        "        if self.motif_data is None:\n",
        "            print('Returning the correlation matrix of expression data in <Panda_obj>.correlation_matrix')\n",
        "            self.panda_network        = self.correlation_matrix\n",
        "            self.export_panda_results = self.correlation_matrix\n",
        "            self.motif_matrix         = self.motif_data\n",
        "            self.ppi_matrix           = self.ppi_data\n",
        "            self.__pearson_results_data_frame()\n",
        "            return\n",
        "\n",
        "\n",
        "        with Timer('Creating motif network ...'):\n",
        "            self.motif_matrix_unnormalized = np.zeros((self.num_tfs, self.num_genes))\n",
        "            idx_tfs = [tf2idx.get(x, 0) for x in self.motif_data[0]]\n",
        "            idx_genes = [gene2idx.get(x, 0) for x in self.motif_data[1]]\n",
        "            idx = np.ravel_multi_index((idx_tfs, idx_genes), self.motif_matrix_unnormalized.shape)\n",
        "            self.motif_matrix_unnormalized.ravel()[idx] = self.motif_data[2]\n",
        "\n",
        "        if self.ppi_data is None:\n",
        "            self.ppi_matrix = np.identity(self.num_tfs,dtype=int)\n",
        "        else:\n",
        "            with Timer('Creating PPI network ...'):\n",
        "                self.ppi_matrix = np.identity(self.num_tfs)\n",
        "                idx_tf1 = [tf2idx.get(x, 0) for x in self.ppi_data[0]]\n",
        "                idx_tf2 = [tf2idx.get(x, 0) for x in self.ppi_data[1]]\n",
        "                idx = np.ravel_multi_index((idx_tf1, idx_tf2), self.ppi_matrix.shape)\n",
        "                self.ppi_matrix.ravel()[idx] = self.ppi_data[2]\n",
        "                idx = np.ravel_multi_index((idx_tf2, idx_tf1), self.ppi_matrix.shape)\n",
        "                self.ppi_matrix.ravel()[idx] = self.ppi_data[2]\n",
        "        \n",
        "        return\n",
        "\n",
        "    def panda_loop(self, correlation_matrix, motif_matrix, ppi_matrix,computing='cpu'):\n",
        "        \"\"\"Panda algorithm.\n",
        "        \"\"\"\n",
        "        def t_function(x, y=None):\n",
        "            '''T function.'''\n",
        "            if y is None:\n",
        "                a_matrix = np.dot(x, x.T)\n",
        "                s = np.square(x).sum(axis=1)\n",
        "                a_matrix /= np.sqrt(s + s.reshape(-1, 1) - np.abs(a_matrix))\n",
        "            else:\n",
        "                a_matrix = np.dot(x, y)\n",
        "                a_matrix /= np.sqrt(np.square(y).sum(axis=0) + np.square(x).sum(axis=1).reshape(-1, 1) - np.abs(a_matrix))\n",
        "            return a_matrix\n",
        "\n",
        "        def update_diagonal(diagonal_matrix, num, alpha, step):\n",
        "            '''Update diagonal.'''\n",
        "            np.fill_diagonal(diagonal_matrix, np.nan)\n",
        "            diagonal_std = np.nanstd(diagonal_matrix, 1)\n",
        "            diagonal_fill = diagonal_std * num * math.exp(2 * alpha * step)\n",
        "            np.fill_diagonal(diagonal_matrix, diagonal_fill)\n",
        "\n",
        "        def gt_function(x, y=None):\n",
        "            '''T function.'''\n",
        "            if y is None:\n",
        "                a_matrix = cp.dot(x, x.T)\n",
        "                s = cp.square(x).sum(axis=1)\n",
        "                a_matrix /= cp.sqrt(s + s.reshape(-1, 1) - cp.abs(a_matrix))\n",
        "            else:\n",
        "                a_matrix = cp.dot(x, y)\n",
        "                a_matrix /= cp.sqrt(cp.square(y).sum(axis=0) + cp.square(x).sum(axis=1).reshape(-1, 1) - cp.abs(a_matrix))\n",
        "            return a_matrix\n",
        "\n",
        "        def gupdate_diagonal(diagonal_matrix, num, alpha, step):\n",
        "            '''Update diagonal.'''\n",
        "            cp.fill_diagonal(diagonal_matrix, cp.nan)\n",
        "            diagonal_std = cp.nanstd(diagonal_matrix, 1)\n",
        "            diagonal_fill = diagonal_std * num * math.exp(2 * alpha * step)\n",
        "            cp.fill_diagonal(diagonal_matrix, diagonal_fill)\n",
        "\n",
        "        panda_loop_time = time.time()\n",
        "        num_tfs, num_genes = motif_matrix.shape\n",
        "        step = 0\n",
        "        hamming = 1\n",
        "        alpha = 0.1\n",
        "        \n",
        "        while hamming > 0.001:\n",
        "            # Update motif_matrix\n",
        "            if computing=='gpu':\n",
        "                import cupy as cp\n",
        "                ppi_matrix=cp.array(ppi_matrix)\n",
        "                motif_matrix=cp.array(motif_matrix)\n",
        "                correlation_matrix=cp.array(correlation_matrix)\n",
        "                W = 0.5 * (gt_function(ppi_matrix, motif_matrix) + gt_function(motif_matrix, correlation_matrix))  # W = (R + A) / 2\n",
        "                hamming = cp.abs(motif_matrix - W).mean()\n",
        "                motif_matrix=cp.array(motif_matrix)\n",
        "                motif_matrix *= (1 - alpha)\n",
        "                motif_matrix += (alpha * W)\n",
        "\n",
        "                if hamming > 0.001:\n",
        "                    # Update ppi_matrix\n",
        "                    ppi = gt_function(motif_matrix)  # t_func(X, X.T)\n",
        "                    gupdate_diagonal(ppi, num_tfs, alpha, step)\n",
        "                    ppi_matrix *= (1 - alpha)\n",
        "                    ppi_matrix += (alpha * ppi)\n",
        "\n",
        "                    # Update correlation_matrix\n",
        "                    motif = gt_function(motif_matrix.T)\n",
        "                    gupdate_diagonal(motif, num_genes, alpha, step)\n",
        "                    correlation_matrix *= (1 - alpha)\n",
        "                    correlation_matrix += (alpha * motif)\n",
        "\n",
        "                    del W, ppi, motif  # release memory for next step\n",
        "\n",
        "            elif computing=='cpu':\n",
        "                W = 0.5 * (t_function(ppi_matrix, motif_matrix) + t_function(motif_matrix, correlation_matrix))  # W = (R + A) / 2\n",
        "                hamming = np.abs(motif_matrix - W).mean()\n",
        "                motif_matrix *= (1 - alpha)\n",
        "                motif_matrix += (alpha * W)\n",
        "\n",
        "                if hamming > 0.001:\n",
        "                    # Update ppi_matrix\n",
        "                    ppi = t_function(motif_matrix)  # t_func(X, X.T)\n",
        "                    update_diagonal(ppi, num_tfs, alpha, step)\n",
        "                    ppi_matrix *= (1 - alpha)\n",
        "                    ppi_matrix += (alpha * ppi)\n",
        "                    \n",
        "                    # Update correlation_matrix\n",
        "                    motif = t_function(motif_matrix.T)\n",
        "                    update_diagonal(motif, num_genes, alpha, step)\n",
        "                    correlation_matrix *= (1 - alpha)\n",
        "                    correlation_matrix += (alpha * motif)\n",
        "\n",
        "                    del W, ppi, motif  # release memory for next step\n",
        "\n",
        "            print('step: {}, hamming: {}'.format(step, hamming))\n",
        "            step = step + 1\n",
        "\n",
        "        print('Running panda took: %.2f seconds!' % (time.time() - panda_loop_time))\n",
        "        #Ale: reintroducing the export_panda_results array if Panda called with save_memory=False\n",
        "        if computing=='gpu':\n",
        "            motif_matrix=cp.asnumpy(motif_matrix)\n",
        "        if hasattr(self,'unique_tfs'):\n",
        "            tfs = np.tile(self.unique_tfs, (len(self.gene_names), 1)).flatten()\n",
        "            genes = np.repeat(self.gene_names,self.num_tfs)\n",
        "            motif = self.motif_matrix_unnormalized.flatten(order='F')\n",
        "            force = motif_matrix.flatten(order='F')\n",
        "            self.export_panda_results = pd.DataFrame({'tf':tfs, 'gene': genes,'motif': motif, 'force': force})\n",
        "            #self.export_panda_results = np.column_stack((tfs,genes,motif,force))\n",
        "        return motif_matrix\n",
        "\n",
        "    def __pearson_results_data_frame(self):\n",
        "        '''Results to data frame.'''\n",
        "        genes_1 = np.tile(self.gene_names, (len(self.gene_names), 1)).flatten()\n",
        "        genes_2 = np.tile(self.gene_names, (len(self.gene_names), 1)).transpose().flatten()\n",
        "        self.flat_panda_network = self.panda_network.transpose().flatten()\n",
        "        self.export_panda_results = pd.DataFrame({'tf':genes_1, 'gene':genes_2, 'force':self.flat_panda_network})\n",
        "        self.export_panda_results = self.export_panda_results[['tf', 'gene', 'force']]\n",
        "        return None\n",
        "\n",
        "    def save_panda_results(self, path='panda.npy'):\n",
        "        with Timer('Saving PANDA network to %s ...' % path):\n",
        "            #Because there are two modes of operation (save_memory), save to file will be different\n",
        "            if hasattr(self,'panda_network'):\n",
        "                toexport = self.panda_network\n",
        "            else:\n",
        "                toexport = self.export_panda_results\n",
        "            #Export to file\n",
        "            if path.endswith('.txt'):\n",
        "                np.savetxt(path, toexport,fmt='%s', delimiter=' ')\n",
        "            elif path.endswith('.csv'):\n",
        "                np.savetxt(path, toexport,fmt='%s', delimiter=',')\n",
        "            elif path.endswith('.tsv'):\n",
        "                np.savetxt(path, toexport,fmt='%s', delimiter='/t')\n",
        "            else:\n",
        "                np.save(path, toexport)\n",
        "    def top_network_plot(self, top = 100, file = 'panda_top_100.png',plot_bipart=False):\n",
        "        '''Select top genes.'''\n",
        "        if not hasattr(self,'export_panda_results'):\n",
        "            raise AttributeError(\"Panda object does not contain the export_panda_results attribute.\\n\"+\n",
        "                \"Run Panda with the flag save_memory=False\")\n",
        "        #Ale TODO: work in numpy instead of pandas?\n",
        "        self.panda_results = pd.DataFrame(self.export_panda_results, columns=['tf','gene','motif','force'])\n",
        "        subset_panda_results = self.panda_results.sort_values(by=['force'], ascending=False)\n",
        "        subset_panda_results = subset_panda_results[subset_panda_results.tf != subset_panda_results.gene]\n",
        "        subset_panda_results = subset_panda_results[0:top]\n",
        "        self.__shape_plot_network(subset_panda_results = subset_panda_results, file = file, plot_bipart=plot_bipart)\n",
        "        return None\n",
        "    def __shape_plot_network(self, subset_panda_results, file = 'panda.png',plot_bipart=False):\n",
        "        '''Create plot.'''\n",
        "        #reshape data for networkx\n",
        "        unique_genes = list(set(list(subset_panda_results['tf'])+list(subset_panda_results['gene'])))\n",
        "        unique_genes = pd.DataFrame(unique_genes)\n",
        "        unique_genes.columns = ['name']\n",
        "        unique_genes['index'] = unique_genes.index\n",
        "        subset_panda_results = subset_panda_results.merge(unique_genes, how='inner', left_on='tf', right_on='name')\n",
        "        subset_panda_results = subset_panda_results.rename(columns = {'index': 'tf_index'})\n",
        "        subset_panda_results = subset_panda_results.drop(['name'], 1)\n",
        "        subset_panda_results = subset_panda_results.merge(unique_genes, how='inner', left_on='gene', right_on='name')\n",
        "        subset_panda_results = subset_panda_results.rename(columns = {'index': 'gene_index'})\n",
        "        subset_panda_results = subset_panda_results.drop(['name'], 1)\n",
        "        links = subset_panda_results[['tf_index', 'gene_index', 'force']]\n",
        "        self.__create_plot(unique_genes = unique_genes, links = links, file = file,plot_bipart=plot_bipart)\n",
        "        return None\n",
        "    def __create_plot(self, unique_genes, links, file = 'panda.png',plot_bipart=False):\n",
        "        '''Run plot.'''\n",
        "        import networkx as nx\n",
        "        import matplotlib.pyplot as plt\n",
        "        g = nx.Graph()\n",
        "        g.clear()\n",
        "        plt.clf()\n",
        "        #img = plt.imread(\"../img/panda.jpg\")\n",
        "        #fig, ax = plt.subplots()\n",
        "        #ax.imshow(img, extent=[0, 400, 0, 300])\n",
        "        ##ax.plot(x, x, '--', linewidth=5, color='firebrick')\n",
        "        g.add_nodes_from(unique_genes['index'])\n",
        "        edges = []\n",
        "        for i in range(0, len(links)):\n",
        "            edges = edges + [(links.iloc[i]['tf_index'], links.iloc[i]['gene_index'], float(links.iloc[i]['force'])/200)]\n",
        "        g.add_weighted_edges_from(edges)\n",
        "        labels = {}\n",
        "        def split_label(label):\n",
        "            ll = len(label)\n",
        "            if ll > 6:\n",
        "                return label[0:int(np.ceil(ll/2))] + '\\n' + label[int(np.ceil(ll/2)):]\n",
        "            return label\n",
        "        for i, l in enumerate(unique_genes.iloc[:,0]):\n",
        "            labels[i] = split_label(l)\n",
        "        if not plot_bipart:\n",
        "            pos = nx.spring_layout(g)\n",
        "        else:\n",
        "            pos = nx.drawing.layout.bipartite_layout(g, set(links['tf_index']))\n",
        "        #nx.draw_networkx(g, pos, labels=labels, node_size=40, font_size=3, alpha=0.3, linewidth = 0.5, width =0.5)\n",
        "        print(plot_bipart)\n",
        "        if not plot_bipart:\n",
        "            colors=range(len(edges))\n",
        "        else:\n",
        "            colors=list(zip(*edges))[-1]\n",
        "                                                     \n",
        "        options = {'alpha': 0.7, 'edge_color': colors, 'edge_cmap': plt.cm.Blues, 'node_size' :110, 'vmin': -100,\n",
        "                   'width': 2, 'labels': labels, 'font_weight': 'regular', 'font_size': 3, 'linewidth': 20}\n",
        "        \n",
        "        nx.draw_networkx(g, k=0.25, iterations=50, pos=pos,**options)\n",
        "        plt.axis('off')\n",
        "        plt.savefig(file, dpi=300)\n",
        "        return None\n",
        "\n",
        "    def return_panda_indegree(self):\n",
        "        '''Return Panda indegree.'''\n",
        "        export_panda_results_pd = pd.DataFrame(self.export_panda_results,columns=['tf','gene','motif','force'])\n",
        "        subset_indegree = export_panda_results_pd.loc[:,['gene','force']]\n",
        "        self.panda_indegree = subset_indegree.groupby('gene').sum()\n",
        "        return self.panda_indegree\n",
        "    def return_panda_outdegree(self):\n",
        "        '''Return Panda outdegree.'''\n",
        "        export_panda_results_pd = pd.DataFrame(self.export_panda_results,columns=['tf','gene','motif','force'])\n",
        "        subset_outdegree = export_panda_results_pd.loc[:,['tf','force']]\n",
        "        self.panda_outdegree = subset_outdegree.groupby('tf').sum()\n",
        "        return self.panda_outdegree\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rz4ahjpAgkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"A tic-toc analog in Python\n",
        "\n",
        "Adapted from http://stackoverflow.com/questions/5849800/tic-toc-functions-analog-in-python\n",
        "\"\"\"\n",
        "import time\n",
        "\n",
        "class Timer(object):\n",
        "    def __init__(self, name=None):\n",
        "        if name:\n",
        "            print(name)\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.tic = time.time()\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        print('  Elapsed time: %.2f sec.' % (time.time() - self.tic))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxF-Jd5bArmj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "21869524-31e6-4e34-a027-38e0beec1344"
      },
      "source": [
        "!git clone --single-branch --branch milipeed https://github.com/dcolinmorgan/netZooPy.git\n",
        "# os.chdir('netZooPy')\n",
        "# !pip install -e ./"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'netZooPy'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 3210 (delta 30), reused 35 (delta 20), pack-reused 3150\u001b[K\n",
            "Receiving objects: 100% (3210/3210), 173.51 MiB | 20.30 MiB/s, done.\n",
            "Resolving deltas: 100% (1314/1314), done.\n",
            "Checking out files: 100% (352/352), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSuJllFJAg1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "89a6020d-a3e8-4709-cf3d-51c3f6d7dec5"
      },
      "source": [
        "panda_obj=Panda('netZooPy/tests/puma/ToyData/ToyExpressionData.txt',\n",
        "                'netZooPy/tests/puma/ToyData/ToyMotifData.txt',\n",
        "                'netZooPy/tests/puma/ToyData/ToyPPIData.txt',\n",
        "    computing='cpu',precision='double',save_memory = False, save_tmp=False, \n",
        "    remove_missing= True, keep_expression_matrix = False,\n",
        "     modeProcess = 'intersection')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading motif data ...\n",
            "  Elapsed time: 0.03 sec.\n",
            "Loading expression data ...\n",
            "  Elapsed time: 0.02 sec.\n",
            "Loading PPI data ...\n",
            "Number of PPIs: 238\n",
            "  Elapsed time: 0.00 sec.\n",
            "Remove expression not in motif:\n",
            "   87 rows removed from the initial 1000\n",
            "Remove motif not in expression data:\n",
            "   0 rows removed from the initial 14597\n",
            "Remove ppi not in motif:\n",
            "   0 rows removed from the initial 238\n",
            "(913, 50)\n",
            "(913, 50)\n",
            "Calculating coexpression network ...\n",
            "  Elapsed time: 0.02 sec.\n",
            "Creating motif network ...\n",
            "  Elapsed time: 0.02 sec.\n",
            "Creating PPI network ...\n",
            "  Elapsed time: 0.00 sec.\n",
            "Normalizing networks ...\n",
            "  Elapsed time: 0.04 sec.\n",
            "Running PANDA algorithm ...\n",
            "step: 0, hamming: 0.7798917226715182\n",
            "step: 1, hamming: 0.4511379283450311\n",
            "step: 2, hamming: 0.518685514316148\n",
            "step: 3, hamming: 0.555300393166025\n",
            "step: 4, hamming: 0.5728475146737425\n",
            "step: 5, hamming: 0.5766241758460399\n",
            "step: 6, hamming: 0.5689601133089167\n",
            "step: 7, hamming: 0.5515789177300447\n",
            "step: 8, hamming: 0.5262246706690599\n",
            "step: 9, hamming: 0.4947831876631561\n",
            "step: 10, hamming: 0.4590910225472031\n",
            "step: 11, hamming: 0.4208788960432843\n",
            "step: 12, hamming: 0.38166815748959326\n",
            "step: 13, hamming: 0.3427177973625151\n",
            "step: 14, hamming: 0.3050160548238351\n",
            "step: 15, hamming: 0.2692890750501229\n",
            "step: 16, hamming: 0.23602872335494865\n",
            "step: 17, hamming: 0.2055261731557181\n",
            "step: 18, hamming: 0.1779104786846009\n",
            "step: 19, hamming: 0.1531853925472216\n",
            "step: 20, hamming: 0.13126216807246605\n",
            "step: 21, hamming: 0.11198784327672719\n",
            "step: 22, hamming: 0.09516868953648845\n",
            "step: 23, hamming: 0.08058872386166728\n",
            "step: 24, hamming: 0.0680236694822223\n",
            "step: 25, hamming: 0.05725129701349013\n",
            "step: 26, hamming: 0.04805856895803554\n",
            "step: 27, hamming: 0.04024625373875233\n",
            "step: 28, hamming: 0.03363159225178915\n",
            "step: 29, hamming: 0.028049512993310672\n",
            "step: 30, hamming: 0.02335280980804773\n",
            "step: 31, hamming: 0.019411588728599747\n",
            "step: 32, hamming: 0.01611226064500626\n",
            "step: 33, hamming: 0.013356245515384993\n",
            "step: 34, hamming: 0.011058551988398724\n",
            "step: 35, hamming: 0.00914632218272669\n",
            "step: 36, hamming: 0.007557409912691694\n",
            "step: 37, hamming: 0.006239034872915106\n",
            "step: 38, hamming: 0.005146545487932827\n",
            "step: 39, hamming: 0.004242294882640481\n",
            "step: 40, hamming: 0.003494637629986917\n",
            "step: 41, hamming: 0.002877044453465467\n",
            "step: 42, hamming: 0.002367328335163773\n",
            "step: 43, hamming: 0.0019469734531065523\n",
            "step: 44, hamming: 0.0016005572951987837\n",
            "step: 45, hamming: 0.001315255889078734\n",
            "step: 46, hamming: 0.0010804224436477337\n",
            "step: 47, hamming: 0.0008872299366588595\n",
            "Running panda took: 2.02 seconds!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlE2qNzEAnVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23d5f4df-1fa8-4489-fd50-632da3c27002"
      },
      "source": [
        "panda_obj.panda_network.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74, 913)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcwBste2A653",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "# from .timer import Timer\n",
        "import numpy as np\n",
        "\n",
        "class Panda2(object):\n",
        "    \"\"\" \n",
        "    Description:\n",
        "       Using PANDA to infer gene regulatory network.\n",
        "\n",
        "    Usage:\n",
        "        1. Reading in input data (expression data, motif prior, TF PPI data)\n",
        "        2. Computing coexpression network\n",
        "        3. Normalizing networks\n",
        "        4. Running PANDA algorithm\n",
        "        5. Writing out PANDA network\n",
        "\n",
        "    Inputs:\n",
        "        motif_data: path to file containing the transcription factor DNA binding motif data in the form of TF-gene-weight(0/1).\n",
        "                    if set to none, the gene coexpression matrix is returned as a result network.\n",
        "        save_memory: True : removes temporary results from memory. The result network is weighted adjacency matrix of size (nTFs, nGenes).\n",
        "                     False: keeps the temporary files in memory. The result network has 4 columns in the form gene - TF - weight in motif prior - PANDA edge.\n",
        "        keep_expression_matrix: keeps the input expression matrix in the result Panda object.\n",
        "        modeProcess: The input data processing mode.\n",
        "                    'legacy': refers to the processing mode in netZooPy<=0.5\n",
        "                    (Default)'union': takes the union of all TFs and genes across priors and fills the missing genes in the priors with zeros.\n",
        "                    'intersection': intersects the input genes and TFs across priors and removes the missing TFs/genes.\n",
        "        remove_missing: removes the gens and TFs that are not present in one of the priors. Works only if modeProcess='legacy'\n",
        "        computing  : 'cpu' uses Central Processing Unit (CPU) to run PANDA\n",
        "                     'gpu' use the Graphical Processing Unit (GPU) to run PANDA\n",
        "        precision  : 'double' computes the regulatory network in double precision (15 decimal digits)\n",
        "                     'single' computes the regulatory network in single precision (7 decimal digits) which is fastaer, requires half the memory but less accurate.\n",
        "                      \n",
        "     Methods:\n",
        "        return_panda_indegree: computes indegree of panda network, only if save_memory = False\n",
        "        return_panda_outdegree: computes outdegree of panda network, only if save_memory = False\n",
        "\n",
        "    Outputs:\n",
        "\n",
        "     Authors: \n",
        "       cychen, davidvi, alessandromarin, Marouen Ben Guebila, Daniel Morgan\n",
        "    \"\"\"\n",
        "    def __init__(self, expression_file, motif_file, ppi_file, computing='cpu',precision='double',save_memory = False, save_tmp=True, remove_missing=False, keep_expression_matrix = False, modeProcess = 'union'):\n",
        "        \n",
        "        # Read data\n",
        "        self.processData(modeProcess, motif_file, expression_file, ppi_file, remove_missing, keep_expression_matrix)\n",
        "        if hasattr(self, 'export_panda_results'):\n",
        "            return\n",
        "        \n",
        "        # =====================================================================\n",
        "        # Network normalization\n",
        "        # =====================================================================\n",
        "\n",
        "        with Timer('Normalizing networks ...'):\n",
        "            self.correlation_matrix = self._normalize_network(self.correlation_matrix)\n",
        "            with np.errstate(invalid='ignore'): #silly warning bothering people\n",
        "                self.motif_matrix = self._normalize_network(self.motif_matrix_unnormalized)\n",
        "            self.ppi_matrix = self._normalize_network(self.ppi_matrix)\n",
        "            if precision=='single':\n",
        "                self.correlation_matrix=np.float32(self.correlation_matrix)\n",
        "                self.motif_matrix=np.float32(self.motif_matrix)\n",
        "                self.ppi_matrix=np.float32(self.ppi_matrix)\n",
        "        # =====================================================================\n",
        "        # Clean up useless variables to release memory\n",
        "        # =====================================================================\n",
        "        if save_memory:\n",
        "            print(\"Clearing motif and ppi data, unique tfs, and gene names for speed\")\n",
        "            del self.unique_tfs, self.gene_names, self.motif_matrix_unnormalized\n",
        "\n",
        "        # =====================================================================\n",
        "        # Saving middle data to tmp\n",
        "        # =====================================================================\n",
        "        if save_tmp:\n",
        "            with Timer('Saving expression matrix and normalized networks ...'):\n",
        "                if self.expression_data is not None:\n",
        "                    np.save('/tmp/expression.npy', self.expression_data.values)\n",
        "                np.save('/tmp/motif.normalized.npy', self.motif_matrix)\n",
        "                np.save('/tmp/ppi.normalized.npy', self.ppi_matrix)\n",
        "\n",
        "        # delete expression data\n",
        "        del self.expression_data\n",
        "\n",
        "        # =====================================================================\n",
        "        # Running PANDA algorithm\n",
        "        # =====================================================================\n",
        "        if self.motif_data is not None:\n",
        "            print('Running PANDA algorithm ...')\n",
        "            self.panda_network = self.panda_loop(self.correlation_matrix, self.motif_matrix, self.ppi_matrix,computing)\n",
        "        else:\n",
        "            self.panda_network = self.correlation_matrix\n",
        "            self.__pearson_results_data_frame()\n",
        "\n",
        "\n",
        "    def __remove_missing(self):\n",
        "        '''Remove genes and tfs not present in all files.'''\n",
        "        if self.expression_data is not None:\n",
        "            print(\"Remove expression not in motif:\")\n",
        "            motif_unique_genes = set(self.motif_data[1])\n",
        "            len_tot = len(self.expression_data)\n",
        "            self.expression_data = self.expression_data[self.expression_data.index.isin(motif_unique_genes)]\n",
        "            self.gene_names = self.expression_data.index.tolist()\n",
        "            self.num_genes = len(self.gene_names)\n",
        "            print(\"   {} rows removed from the initial {}\".format(len_tot-self.num_genes,len_tot))\n",
        "        #if self.motif_data is not None:\n",
        "        print(\"Remove motif not in expression data:\")\n",
        "        len_tot = len(self.motif_data)\n",
        "        self.motif_data = self.motif_data[self.motif_data.iloc[:,1].isin(self.gene_names)]\n",
        "        self.unique_tfs = sorted(set(self.motif_data[0]))\n",
        "        self.num_tfs = len(self.unique_tfs)\n",
        "        print(\"   {} rows removed from the initial {}\".format(len_tot-len(self.motif_data),len_tot))\n",
        "        if self.ppi_data is not None:\n",
        "            print(\"Remove ppi not in motif:\")\n",
        "            motif_unique_tfs = np.unique(self.motif_data.iloc[:,0])\n",
        "            len_tot = len(self.ppi_data)\n",
        "            self.ppi_data = self.ppi_data[self.ppi_data.iloc[:,0].isin(motif_unique_tfs)]\n",
        "            self.ppi_data = self.ppi_data[self.ppi_data.iloc[:,1].isin(motif_unique_tfs)]\n",
        "            print(\"   {} rows removed from the initial {}\".format(len_tot-len(self.ppi_data),len_tot))\n",
        "        return None\n",
        "\n",
        "    def _normalize_network(self, x):\n",
        "        norm_col = zscore(x, axis=0)\n",
        "        if x.shape[0] == x.shape[1]:\n",
        "            norm_row = norm_col.T\n",
        "        else:\n",
        "            norm_row = zscore(x, axis=1)\n",
        "        #Alessandro: replace nan values\n",
        "        normalized_matrix = (norm_col + norm_row) / math.sqrt(2)\n",
        "        norm_total = (x-np.mean(x))/np.std(x)   #NB zscore(x) is not the same\n",
        "        nan_col = np.isnan(norm_col)\n",
        "        nan_row = np.isnan(norm_row)\n",
        "        normalized_matrix[nan_col] = (norm_row[nan_col] + norm_total[nan_col])/math.sqrt(2)\n",
        "        normalized_matrix[nan_row] = (norm_col[nan_row] + norm_total[nan_row])/math.sqrt(2)\n",
        "        normalized_matrix[nan_col & nan_row] = 2*norm_total[nan_col & nan_row]/math.sqrt(2)\n",
        "        return normalized_matrix\n",
        "\n",
        "    def processData(self, modeProcess, motif_file, expression_file, ppi_file, remove_missing, keep_expression_matrix):\n",
        "        # if modeProcess==\"legacy\":\n",
        "        # =====================================================================\n",
        "        # Data loading\n",
        "        # =====================================================================\n",
        "        if type(motif_file) is str:\n",
        "            with Timer('Loading motif data ...'):\n",
        "                self.motif_data = pd.read_csv(motif_file, sep='\\t', header=None)\n",
        "                self.motif_tfs = sorted(set(self.motif_data[0]))\n",
        "                self.motif_genes = sorted(set(self.motif_data[1]))\n",
        "                # self.num_tfs = len(self.unique_tfs)\n",
        "                # print('Unique TFs:', self.num_tfs)\n",
        "        elif type(motif_file) is not str:\n",
        "            self.motif_data = pd.DataFrame(motif_file.values)#pd.read_csv(motif_file, sep='\\t', header=None)\n",
        "            self.motif_tfs = sorted(set(motif_file['source']))\n",
        "            self.motif_genes = sorted(set(motif_file['target']))\n",
        "            # self.num_tfs = len(self.unique_tfs)\n",
        "            # print('Unique TFs:', self.num_tfs)\n",
        "\n",
        "        else:\n",
        "            self.motif_data = None\n",
        "\n",
        "        if type(expression_file) is str:\n",
        "            with Timer('Loading expression data ...'):\n",
        "                self.expression_data = pd.read_csv(expression_file, sep='\\t', header=None, index_col=0)\n",
        "                self.expression_genes = self.expression_data.index.tolist()\n",
        "                # self.num_genes = len(self.gene_names)\n",
        "                # print('Expression matrix:', self.expression_data.shape)\n",
        "        elif type(expression_file) is not str:\n",
        "            self.expression_data = expression_file #pd.read_csv(expression_file, sep='\\t', header=None, index_col=0)\n",
        "            self.expression_genes = self.expression_data.index.tolist()\n",
        "            # self.num_genes = len(self.gene_names)\n",
        "            # print('Expression matrix:', self.expression_data.shape)\n",
        "        else:\n",
        "            self.gene_names = list(set(self.motif_data[1]))\n",
        "            self.num_genes = len(self.gene_names)\n",
        "            self.expression_data = None #pd.DataFrame(np.identity(self.num_genes, dtype=int))\n",
        "            print('No Expression data given: correlation matrix will be an identity matrix of size', self.num_genes)\n",
        "\n",
        "        if type(ppi_file) is str:\n",
        "            with Timer('Loading PPI data ...'):\n",
        "                self.ppi_data = pd.read_csv(ppi_file, sep='\\t', header=None)\n",
        "                self.ppi_tfs  = sorted(set(self.ppi_data[0]))\n",
        "                print('Number of PPIs:', self.ppi_data.shape[0])\n",
        "        elif type(ppi_file) is not str:\n",
        "            self.ppi_data = ppi_file#pd.read_csv(ppi_file, sep='\\t', header=None)\n",
        "            self.ppi_tfs  = sorted(set(self.ppi_data[0]))\n",
        "            print('Number of PPIs:', self.ppi_data.shape[0])\n",
        "        else:\n",
        "            print('No PPI data given: ppi matrix will be an identity matrix of size', self.num_tfs)\n",
        "            self.ppi_data = None\n",
        "\n",
        "        if remove_missing and motif_file is not None:\n",
        "            self.__remove_missing()\n",
        "        \n",
        "        if modeProcess==\"legacy\":\n",
        "            self.gene_names = self.expression_genes#sorted( np.unique(self.motif_genes +  self.expression_genes ))\n",
        "            self.unique_tfs = self.motif_tfs#sorted( np.unique(self.ppi_tfs     +  self.motif_tfs ))\n",
        "\n",
        "        elif modeProcess==\"union\":\n",
        "            self.gene_names = sorted( np.unique(self.motif_genes +  self.expression_genes ))\n",
        "            self.unique_tfs = sorted( np.unique(self.ppi_tfs     +  self.motif_tfs ))\n",
        "\n",
        "        elif modeProcess==\"intersection\":\n",
        "            self.gene_names = sorted(np.unique( list(set(self.motif_genes).intersection(set(self.expression_genes))) ))\n",
        "            self.unique_tfs = sorted(np.unique( list(set(self.ppi_tfs).intersection(set(self.motif_tfs)) )))\n",
        "        \n",
        "        self.num_genes  = len(self.gene_names)\n",
        "        self.num_tfs    = len(self.unique_tfs)\n",
        "\n",
        "        # Auxiliary dicts\n",
        "        gene2idx = {x: i for i,x in enumerate(self.gene_names)}\n",
        "        tf2idx = {x: i for i,x in enumerate(self.unique_tfs)}\n",
        "        if modeProcess==\"union\" or modeProcess==\"intersection\":\n",
        "            # Initialize data & Populate gene expression\n",
        "            self.expression = np.zeros((self.num_genes, self.expression_data.shape[1]))\n",
        "            print(self.expression.shape)\n",
        "            print(self.expression_data.shape)\n",
        "            # if modeProcess==\"union\":\n",
        "            idx_geneEx = [gene2idx.get(x, 0) for x in self.expression_genes]\n",
        "            # else:\n",
        "            #     idx_geneEx = [gene2idx.get(x, 0) for x in self.gene_names]\n",
        "            self.expression[idx_geneEx,:] = self.expression_data.values\n",
        "            self.expression_data=pd.DataFrame(data=self.expression)\n",
        "\n",
        "        # =====================================================================\n",
        "        # Network construction\n",
        "        # =====================================================================\n",
        "        with Timer('Calculating coexpression network ...'):\n",
        "            if self.expression_data is None:\n",
        "                self.correlation_matrix = np.identity(self.num_genes,dtype=int)\n",
        "            else:\n",
        "                self.correlation_matrix = np.corrcoef(self.expression_data)\n",
        "            if np.isnan(self.correlation_matrix).any():\n",
        "                np.fill_diagonal(self.correlation_matrix, 1)\n",
        "                self.correlation_matrix = np.nan_to_num(self.correlation_matrix)\n",
        "\n",
        "        # Clean up useless variables to release memory\n",
        "        if keep_expression_matrix:\n",
        "            self.expression_matrix = self.expression_data.values\n",
        "\n",
        "        if self.motif_data is None:\n",
        "            print('Returning the correlation matrix of expression data in <Panda_obj>.correlation_matrix')\n",
        "            self.panda_network        = self.correlation_matrix\n",
        "            self.export_panda_results = self.correlation_matrix\n",
        "            self.motif_matrix         = self.motif_data\n",
        "            self.ppi_matrix           = self.ppi_data\n",
        "            self.__pearson_results_data_frame()\n",
        "            return\n",
        "\n",
        "\n",
        "        with Timer('Creating motif network ...'):\n",
        "            self.motif_matrix_unnormalized = np.zeros((self.num_tfs, self.num_genes))\n",
        "            idx_tfs = [tf2idx.get(x, 0) for x in self.motif_data[0]]\n",
        "            idx_genes = [gene2idx.get(x, 0) for x in self.motif_data[1]]\n",
        "            idx = np.ravel_multi_index((idx_tfs, idx_genes), self.motif_matrix_unnormalized.shape)\n",
        "            self.motif_matrix_unnormalized.ravel()[idx] = self.motif_data[2]\n",
        "\n",
        "        if self.ppi_data is None:\n",
        "            self.ppi_matrix = np.identity(self.num_tfs,dtype=int)\n",
        "        else:\n",
        "            with Timer('Creating PPI network ...'):\n",
        "                self.ppi_matrix = np.identity(self.num_tfs)\n",
        "                idx_tf1 = [tf2idx.get(x, 0) for x in self.ppi_data[0]]\n",
        "                idx_tf2 = [tf2idx.get(x, 0) for x in self.ppi_data[1]]\n",
        "                idx = np.ravel_multi_index((idx_tf1, idx_tf2), self.ppi_matrix.shape)\n",
        "                self.ppi_matrix.ravel()[idx] = self.ppi_data[2]\n",
        "                idx = np.ravel_multi_index((idx_tf2, idx_tf1), self.ppi_matrix.shape)\n",
        "                self.ppi_matrix.ravel()[idx] = self.ppi_data[2]\n",
        "        \n",
        "        return\n",
        "\n",
        "    def panda_loop(self, correlation_matrix, motif_matrix, ppi_matrix,computing='cpu'):\n",
        "        \"\"\"Panda algorithm.\n",
        "        \"\"\"\n",
        "        def t_function(x, y=None):\n",
        "            '''T function.'''\n",
        "            if y is None:\n",
        "                a_matrix = np.dot(x, x.T)\n",
        "                s = np.square(x).sum(axis=1)\n",
        "                a_matrix /= np.sqrt(s + s.reshape(-1, 1) - np.abs(a_matrix))\n",
        "            else:\n",
        "                a_matrix = np.dot(x, y)\n",
        "                a_matrix /= np.sqrt(np.square(y).sum(axis=0) + np.square(x).sum(axis=1).reshape(-1, 1) - np.abs(a_matrix))\n",
        "            return a_matrix\n",
        "\n",
        "        def update_diagonal(diagonal_matrix, num, alpha, step):\n",
        "            '''Update diagonal.'''\n",
        "            np.fill_diagonal(diagonal_matrix, np.nan)\n",
        "            diagonal_std = np.nanstd(diagonal_matrix, 1)\n",
        "            diagonal_fill = diagonal_std * num * math.exp(2 * alpha * step)\n",
        "            np.fill_diagonal(diagonal_matrix, diagonal_fill)\n",
        "\n",
        "        def gt_function(x, y=None):\n",
        "            '''T function.'''\n",
        "            if y is None:\n",
        "                a_matrix = cp.dot(x, x.T)\n",
        "                s = cp.square(x).sum(axis=1)\n",
        "                a_matrix /= cp.sqrt(s + s.reshape(-1, 1) - cp.abs(a_matrix))\n",
        "            else:\n",
        "                a_matrix = cp.dot(x, y)\n",
        "                a_matrix /= cp.sqrt(cp.square(y).sum(axis=0) + cp.square(x).sum(axis=1).reshape(-1, 1) - cp.abs(a_matrix))\n",
        "            return a_matrix\n",
        "\n",
        "        def gupdate_diagonal(diagonal_matrix, num, alpha, step):\n",
        "            '''Update diagonal.'''\n",
        "            cp.fill_diagonal(diagonal_matrix, cp.nan)\n",
        "            diagonal_std = cp.nanstd(diagonal_matrix, 1)\n",
        "            diagonal_fill = diagonal_std * num * math.exp(2 * alpha * step)\n",
        "            cp.fill_diagonal(diagonal_matrix, diagonal_fill)\n",
        "\n",
        "        panda_loop_time = time.time()\n",
        "        num_tfs, num_genes = motif_matrix.shape\n",
        "        step = 0\n",
        "        hamming = 1\n",
        "        alpha = 0.1\n",
        "        \n",
        "        while hamming > 0.001:\n",
        "            # Update motif_matrix\n",
        "            if computing=='gpu':\n",
        "                import cupy as cp\n",
        "                ppi_matrix=cp.array(ppi_matrix)\n",
        "                motif_matrix=cp.array(motif_matrix)\n",
        "                correlation_matrix=cp.array(correlation_matrix)\n",
        "                W = 0.5 * (gt_function(ppi_matrix, motif_matrix) + gt_function(motif_matrix, correlation_matrix))  # W = (R + A) / 2\n",
        "                hamming = cp.abs(motif_matrix - W).mean()\n",
        "                motif_matrix=cp.array(motif_matrix)\n",
        "                motif_matrix *= (1 - alpha)\n",
        "                motif_matrix += (alpha * W)\n",
        "\n",
        "                if hamming > 0.001:\n",
        "                    # Update ppi_matrix\n",
        "                    ppi = gt_function(motif_matrix)  # t_func(X, X.T)\n",
        "                    gupdate_diagonal(ppi, num_tfs, alpha, step)\n",
        "                    ppi_matrix *= (1 - alpha)\n",
        "                    ppi_matrix += (alpha * ppi)\n",
        "\n",
        "                    # Update correlation_matrix\n",
        "                    motif = gt_function(motif_matrix.T)\n",
        "                    gupdate_diagonal(motif, num_genes, alpha, step)\n",
        "                    correlation_matrix *= (1 - alpha)\n",
        "                    correlation_matrix += (alpha * motif)\n",
        "\n",
        "                    del W, ppi, motif  # release memory for next step\n",
        "\n",
        "            elif computing=='cpu':\n",
        "                W = 0.5 * (t_function(ppi_matrix, motif_matrix) + t_function(motif_matrix, correlation_matrix))  # W = (R + A) / 2\n",
        "                hamming = np.abs(motif_matrix - W).mean()\n",
        "                motif_matrix *= (1 - alpha)\n",
        "                motif_matrix += (alpha * W)\n",
        "\n",
        "                if hamming > 0.001:\n",
        "                    # Update ppi_matrix\n",
        "                    ppi = t_function(motif_matrix)  # t_func(X, X.T)\n",
        "                    update_diagonal(ppi, num_tfs, alpha, step)\n",
        "                    ppi_matrix *= (1 - alpha)\n",
        "                    ppi_matrix += (alpha * ppi)\n",
        "                    \n",
        "                    # Update correlation_matrix\n",
        "                    motif = t_function(motif_matrix.T)\n",
        "                    update_diagonal(motif, num_genes, alpha, step)\n",
        "                    correlation_matrix *= (1 - alpha)\n",
        "                    correlation_matrix += (alpha * motif)\n",
        "\n",
        "                    del W, ppi, motif  # release memory for next step\n",
        "\n",
        "            print('step: {}, hamming: {}'.format(step, hamming))\n",
        "            step = step + 1\n",
        "\n",
        "        print('Running panda took: %.2f seconds!' % (time.time() - panda_loop_time))\n",
        "        #Ale: reintroducing the export_panda_results array if Panda called with save_memory=False\n",
        "        if computing=='gpu':\n",
        "            motif_matrix=cp.asnumpy(motif_matrix)\n",
        "        if hasattr(self,'unique_tfs'):\n",
        "            tfs = np.tile(self.unique_tfs, (len(self.gene_names), 1)).flatten()\n",
        "            genes = np.repeat(self.gene_names,self.num_tfs)\n",
        "            motif = self.motif_matrix_unnormalized.flatten(order='F')\n",
        "            force = motif_matrix.flatten(order='F')\n",
        "            self.export_panda_results = pd.DataFrame({'tf':tfs, 'gene': genes,'motif': motif, 'force': force})\n",
        "            #self.export_panda_results = np.column_stack((tfs,genes,motif,force))\n",
        "        return motif_matrix\n",
        "\n",
        "    def __pearson_results_data_frame(self):\n",
        "        '''Results to data frame.'''\n",
        "        genes_1 = np.tile(self.gene_names, (len(self.gene_names), 1)).flatten()\n",
        "        genes_2 = np.tile(self.gene_names, (len(self.gene_names), 1)).transpose().flatten()\n",
        "        self.flat_panda_network = self.panda_network.transpose().flatten()\n",
        "        self.export_panda_results = pd.DataFrame({'tf':genes_1, 'gene':genes_2, 'force':self.flat_panda_network})\n",
        "        self.export_panda_results = self.export_panda_results[['tf', 'gene', 'force']]\n",
        "        return None\n",
        "\n",
        "    def save_panda_results(self, path='panda.npy'):\n",
        "        with Timer('Saving PANDA network to %s ...' % path):\n",
        "            #Because there are two modes of operation (save_memory), save to file will be different\n",
        "            if hasattr(self,'panda_network'):\n",
        "                toexport = self.panda_network\n",
        "            else:\n",
        "                toexport = self.export_panda_results\n",
        "            #Export to file\n",
        "            if path.endswith('.txt'):\n",
        "                np.savetxt(path, toexport,fmt='%s', delimiter=' ')\n",
        "            elif path.endswith('.csv'):\n",
        "                np.savetxt(path, toexport,fmt='%s', delimiter=',')\n",
        "            elif path.endswith('.tsv'):\n",
        "                np.savetxt(path, toexport,fmt='%s', delimiter='/t')\n",
        "            else:\n",
        "                np.save(path, toexport)\n",
        "    def top_network_plot(self, top = 100, file = 'panda_top_100.png',plot_bipart=False):\n",
        "        '''Select top genes.'''\n",
        "        if not hasattr(self,'export_panda_results'):\n",
        "            raise AttributeError(\"Panda object does not contain the export_panda_results attribute.\\n\"+\n",
        "                \"Run Panda with the flag save_memory=False\")\n",
        "        #Ale TODO: work in numpy instead of pandas?\n",
        "        self.panda_results = pd.DataFrame(self.export_panda_results, columns=['tf','gene','motif','force'])\n",
        "        subset_panda_results = self.panda_results.sort_values(by=['force'], ascending=False)\n",
        "        subset_panda_results = subset_panda_results[subset_panda_results.tf != subset_panda_results.gene]\n",
        "        subset_panda_results = subset_panda_results[0:top]\n",
        "        self.__shape_plot_network(subset_panda_results = subset_panda_results, file = file, plot_bipart=plot_bipart)\n",
        "        return None\n",
        "    def __shape_plot_network(self, subset_panda_results, file = 'panda.png',plot_bipart=False):\n",
        "        '''Create plot.'''\n",
        "        #reshape data for networkx\n",
        "        unique_genes = list(set(list(subset_panda_results['tf'])+list(subset_panda_results['gene'])))\n",
        "        unique_genes = pd.DataFrame(unique_genes)\n",
        "        unique_genes.columns = ['name']\n",
        "        unique_genes['index'] = unique_genes.index\n",
        "        subset_panda_results = subset_panda_results.merge(unique_genes, how='inner', left_on='tf', right_on='name')\n",
        "        subset_panda_results = subset_panda_results.rename(columns = {'index': 'tf_index'})\n",
        "        subset_panda_results = subset_panda_results.drop(['name'], 1)\n",
        "        subset_panda_results = subset_panda_results.merge(unique_genes, how='inner', left_on='gene', right_on='name')\n",
        "        subset_panda_results = subset_panda_results.rename(columns = {'index': 'gene_index'})\n",
        "        subset_panda_results = subset_panda_results.drop(['name'], 1)\n",
        "        links = subset_panda_results[['tf_index', 'gene_index', 'force']]\n",
        "        self.__create_plot(unique_genes = unique_genes, links = links, file = file,plot_bipart=plot_bipart)\n",
        "        return None\n",
        "    def __create_plot(self, unique_genes, links, file = 'panda.png',plot_bipart=False):\n",
        "        '''Run plot.'''\n",
        "        import networkx as nx\n",
        "        import matplotlib.pyplot as plt\n",
        "        g = nx.Graph()\n",
        "        g.clear()\n",
        "        plt.clf()\n",
        "        #img = plt.imread(\"../img/panda.jpg\")\n",
        "        #fig, ax = plt.subplots()\n",
        "        #ax.imshow(img, extent=[0, 400, 0, 300])\n",
        "        ##ax.plot(x, x, '--', linewidth=5, color='firebrick')\n",
        "        g.add_nodes_from(unique_genes['index'])\n",
        "        edges = []\n",
        "        for i in range(0, len(links)):\n",
        "            edges = edges + [(links.iloc[i]['tf_index'], links.iloc[i]['gene_index'], float(links.iloc[i]['force'])/200)]\n",
        "        g.add_weighted_edges_from(edges)\n",
        "        labels = {}\n",
        "        def split_label(label):\n",
        "            ll = len(label)\n",
        "            if ll > 6:\n",
        "                return label[0:int(np.ceil(ll/2))] + '\\n' + label[int(np.ceil(ll/2)):]\n",
        "            return label\n",
        "        for i, l in enumerate(unique_genes.iloc[:,0]):\n",
        "            labels[i] = split_label(l)\n",
        "        if not plot_bipart:\n",
        "            pos = nx.spring_layout(g)\n",
        "        else:\n",
        "            pos = nx.drawing.layout.bipartite_layout(g, set(links['tf_index']))\n",
        "        #nx.draw_networkx(g, pos, labels=labels, node_size=40, font_size=3, alpha=0.3, linewidth = 0.5, width =0.5)\n",
        "        print(plot_bipart)\n",
        "        if not plot_bipart:\n",
        "            colors=range(len(edges))\n",
        "        else:\n",
        "            colors=list(zip(*edges))[-1]\n",
        "                                                     \n",
        "        options = {'alpha': 0.7, 'edge_color': colors, 'edge_cmap': plt.cm.Blues, 'node_size' :110, 'vmin': -100,\n",
        "                   'width': 2, 'labels': labels, 'font_weight': 'regular', 'font_size': 3, 'linewidth': 20}\n",
        "        \n",
        "        nx.draw_networkx(g, k=0.25, iterations=50, pos=pos,**options)\n",
        "        plt.axis('off')\n",
        "        plt.savefig(file, dpi=300)\n",
        "        return None\n",
        "\n",
        "    def return_panda_indegree(self):\n",
        "        '''Return Panda indegree.'''\n",
        "        export_panda_results_pd = pd.DataFrame(self.export_panda_results,columns=['tf','gene','motif','force'])\n",
        "        subset_indegree = export_panda_results_pd.loc[:,['gene','force']]\n",
        "        self.panda_indegree = subset_indegree.groupby('gene').sum()\n",
        "        return self.panda_indegree\n",
        "    def return_panda_outdegree(self):\n",
        "        '''Return Panda outdegree.'''\n",
        "        export_panda_results_pd = pd.DataFrame(self.export_panda_results,columns=['tf','gene','motif','force'])\n",
        "        subset_outdegree = export_panda_results_pd.loc[:,['tf','force']]\n",
        "        self.panda_outdegree = subset_outdegree.groupby('tf').sum()\n",
        "        return self.panda_outdegree\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra-Ycd_LBIfP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "db2d6fc6-12a1-46b9-a38b-a5d8909a09f3"
      },
      "source": [
        "panda_obj2=Panda2('netZooPy/tests/puma/ToyData/ToyExpressionData.txt',\n",
        "                'netZooPy/tests/puma/ToyData/ToyMotifData.txt',\n",
        "                'netZooPy/tests/puma/ToyData/ToyPPIData.txt',\n",
        "    computing='cpu',precision='double',save_memory = False, save_tmp=False, \n",
        "    remove_missing= True, keep_expression_matrix = False,\n",
        "     modeProcess = 'intersection')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading motif data ...\n",
            "  Elapsed time: 0.02 sec.\n",
            "Loading expression data ...\n",
            "  Elapsed time: 0.02 sec.\n",
            "Loading PPI data ...\n",
            "Number of PPIs: 238\n",
            "  Elapsed time: 0.00 sec.\n",
            "Remove expression not in motif:\n",
            "   87 rows removed from the initial 1000\n",
            "Remove motif not in expression data:\n",
            "   0 rows removed from the initial 14597\n",
            "Remove ppi not in motif:\n",
            "   0 rows removed from the initial 238\n",
            "(913, 50)\n",
            "(913, 50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b0b751b4960c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcomputing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'double'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_tmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mremove_missing\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_expression_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m      modeProcess = 'intersection')\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-6326aad27825>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, expression_file, motif_file, ppi_file, computing, precision, save_memory, save_tmp, remove_missing, keep_expression_matrix, modeProcess)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Read data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodeProcess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmotif_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpression_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppi_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_missing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_expression_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'export_panda_results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-6326aad27825>\u001b[0m in \u001b[0;36mprocessData\u001b[0;34m(self, modeProcess, motif_file, expression_file, ppi_file, remove_missing, keep_expression_matrix)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;31m# else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;31m#     idx_geneEx = [gene2idx.get(x, 0) for x in self.gene_names]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_geneEx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpression_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpression_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shape mismatch: value array of shape (913,50) could not be broadcast to indexing result of shape (1000,50)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxMRtqSeBN48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "# from .timer import Timer\n",
        "import numpy as np\n",
        "\n",
        "class Panda3(object):\n",
        "    \"\"\" \n",
        "    Description:\n",
        "       Using PANDA to infer gene regulatory network.\n",
        "\n",
        "    Usage:\n",
        "        1. Reading in input data (expression data, motif prior, TF PPI data)\n",
        "        2. Computing coexpression network\n",
        "        3. Normalizing networks\n",
        "        4. Running PANDA algorithm\n",
        "        5. Writing out PANDA network\n",
        "\n",
        "    Inputs:\n",
        "        motif_data: path to file containing the transcription factor DNA binding motif data in the form of TF-gene-weight(0/1).\n",
        "                    if set to none, the gene coexpression matrix is returned as a result network.\n",
        "        save_memory: True : removes temporary results from memory. The result network is weighted adjacency matrix of size (nTFs, nGenes).\n",
        "                     False: keeps the temporary files in memory. The result network has 4 columns in the form gene - TF - weight in motif prior - PANDA edge.\n",
        "        keep_expression_matrix: keeps the input expression matrix in the result Panda object.\n",
        "        modeProcess: The input data processing mode.\n",
        "                    'legacy': refers to the processing mode in netZooPy<=0.5\n",
        "                    (Default)'union': takes the union of all TFs and genes across priors and fills the missing genes in the priors with zeros.\n",
        "                    'intersection': intersects the input genes and TFs across priors and removes the missing TFs/genes.\n",
        "        remove_missing: removes the gens and TFs that are not present in one of the priors. Works only if modeProcess='legacy'\n",
        "        computing  : 'cpu' uses Central Processing Unit (CPU) to run PANDA\n",
        "                     'gpu' use the Graphical Processing Unit (GPU) to run PANDA\n",
        "        precision  : 'double' computes the regulatory network in double precision (15 decimal digits)\n",
        "                     'single' computes the regulatory network in single precision (7 decimal digits) which is fastaer, requires half the memory but less accurate.\n",
        "                      \n",
        "     Methods:\n",
        "        return_panda_indegree: computes indegree of panda network, only if save_memory = False\n",
        "        return_panda_outdegree: computes outdegree of panda network, only if save_memory = False\n",
        "\n",
        "    Outputs:\n",
        "\n",
        "     Authors: \n",
        "       cychen, davidvi, alessandromarin, Marouen Ben Guebila, Daniel Morgan\n",
        "    \"\"\"\n",
        "    def __init__(self, expression_file, motif_file, ppi_file, computing='cpu',precision='double',save_memory = False, save_tmp=True, remove_missing=False, keep_expression_matrix = False, modeProcess = 'union'):\n",
        "        \n",
        "        # Read data\n",
        "        self.processData(modeProcess, motif_file, expression_file, ppi_file, remove_missing, keep_expression_matrix)\n",
        "        if hasattr(self, 'export_panda_results'):\n",
        "            return\n",
        "        \n",
        "        # =====================================================================\n",
        "        # Network normalization\n",
        "        # =====================================================================\n",
        "\n",
        "        with Timer('Normalizing networks ...'):\n",
        "            self.correlation_matrix = self._normalize_network(self.correlation_matrix)\n",
        "            with np.errstate(invalid='ignore'): #silly warning bothering people\n",
        "                self.motif_matrix = self._normalize_network(self.motif_matrix_unnormalized)\n",
        "            self.ppi_matrix = self._normalize_network(self.ppi_matrix)\n",
        "            if precision=='single':\n",
        "                self.correlation_matrix=np.float32(self.correlation_matrix)\n",
        "                self.motif_matrix=np.float32(self.motif_matrix)\n",
        "                self.ppi_matrix=np.float32(self.ppi_matrix)\n",
        "        # =====================================================================\n",
        "        # Clean up useless variables to release memory\n",
        "        # =====================================================================\n",
        "        if save_memory:\n",
        "            print(\"Clearing motif and ppi data, unique tfs, and gene names for speed\")\n",
        "            del self.unique_tfs, self.gene_names, self.motif_matrix_unnormalized\n",
        "\n",
        "        # =====================================================================\n",
        "        # Saving middle data to tmp\n",
        "        # =====================================================================\n",
        "        if save_tmp:\n",
        "            with Timer('Saving expression matrix and normalized networks ...'):\n",
        "                if self.expression_data is not None:\n",
        "                    np.save('/tmp/expression.npy', self.expression_data.values)\n",
        "                np.save('/tmp/motif.normalized.npy', self.motif_matrix)\n",
        "                np.save('/tmp/ppi.normalized.npy', self.ppi_matrix)\n",
        "\n",
        "        # delete expression data\n",
        "        del self.expression_data\n",
        "\n",
        "        # =====================================================================\n",
        "        # Running PANDA algorithm\n",
        "        # =====================================================================\n",
        "        if self.motif_data is not None:\n",
        "            print('Running PANDA algorithm ...')\n",
        "            self.panda_network = self.panda_loop(self.correlation_matrix, self.motif_matrix, self.ppi_matrix,computing)\n",
        "        else:\n",
        "            self.panda_network = self.correlation_matrix\n",
        "            self.__pearson_results_data_frame()\n",
        "\n",
        "\n",
        "    def __remove_missing(self):\n",
        "        '''Remove genes and tfs not present in all files.'''\n",
        "        if self.expression_data is not None:\n",
        "            print(\"Remove expression not in motif:\")\n",
        "            motif_unique_genes = set(self.motif_data[1])\n",
        "            len_tot = len(self.expression_data)\n",
        "            self.expression_data = self.expression_data[self.expression_data.index.isin(motif_unique_genes)]\n",
        "            self.gene_names = self.expression_data.index.tolist()\n",
        "            self.num_genes = len(self.gene_names)\n",
        "            print(\"   {} rows removed from the initial {}\".format(len_tot-self.num_genes,len_tot))\n",
        "        #if self.motif_data is not None:\n",
        "        print(\"Remove motif not in expression data:\")\n",
        "        len_tot = len(self.motif_data)\n",
        "        self.motif_data = self.motif_data[self.motif_data.iloc[:,1].isin(self.gene_names)]\n",
        "        self.unique_tfs = sorted(set(self.motif_data[0]))\n",
        "        self.num_tfs = len(self.unique_tfs)\n",
        "        print(\"   {} rows removed from the initial {}\".format(len_tot-len(self.motif_data),len_tot))\n",
        "        if self.ppi_data is not None:\n",
        "            print(\"Remove ppi not in motif:\")\n",
        "            motif_unique_tfs = np.unique(self.motif_data.iloc[:,0])\n",
        "            len_tot = len(self.ppi_data)\n",
        "            self.ppi_data = self.ppi_data[self.ppi_data.iloc[:,0].isin(motif_unique_tfs)]\n",
        "            self.ppi_data = self.ppi_data[self.ppi_data.iloc[:,1].isin(motif_unique_tfs)]\n",
        "            print(\"   {} rows removed from the initial {}\".format(len_tot-len(self.ppi_data),len_tot))\n",
        "        return None\n",
        "\n",
        "    def _normalize_network(self, x):\n",
        "        norm_col = zscore(x, axis=0)\n",
        "        if x.shape[0] == x.shape[1]:\n",
        "            norm_row = norm_col.T\n",
        "        else:\n",
        "            norm_row = zscore(x, axis=1)\n",
        "        #Alessandro: replace nan values\n",
        "        normalized_matrix = (norm_col + norm_row) / math.sqrt(2)\n",
        "        norm_total = (x-np.mean(x))/np.std(x)   #NB zscore(x) is not the same\n",
        "        nan_col = np.isnan(norm_col)\n",
        "        nan_row = np.isnan(norm_row)\n",
        "        normalized_matrix[nan_col] = (norm_row[nan_col] + norm_total[nan_col])/math.sqrt(2)\n",
        "        normalized_matrix[nan_row] = (norm_col[nan_row] + norm_total[nan_row])/math.sqrt(2)\n",
        "        normalized_matrix[nan_col & nan_row] = 2*norm_total[nan_col & nan_row]/math.sqrt(2)\n",
        "        return normalized_matrix\n",
        "\n",
        "    def processData(self, modeProcess, motif_file, expression_file, ppi_file, remove_missing, keep_expression_matrix):\n",
        "        # if modeProcess==\"legacy\":\n",
        "        # =====================================================================\n",
        "        # Data loading\n",
        "        # =====================================================================\n",
        "        if type(motif_file) is str:\n",
        "            with Timer('Loading motif data ...'):\n",
        "                self.motif_data = pd.read_csv(motif_file, sep='\\t', header=None)\n",
        "                self.motif_tfs = sorted(set(self.motif_data[0]))\n",
        "                self.motif_genes = sorted(set(self.motif_data[1]))\n",
        "                # self.num_tfs = len(self.unique_tfs)\n",
        "                # print('Unique TFs:', self.num_tfs)\n",
        "        elif type(motif_file) is not str:\n",
        "            self.motif_data = pd.DataFrame(motif_file.values)#pd.read_csv(motif_file, sep='\\t', header=None)\n",
        "            self.motif_tfs = sorted(set(motif_file['source']))\n",
        "            self.motif_genes = sorted(set(motif_file['target']))\n",
        "            # self.num_tfs = len(self.unique_tfs)\n",
        "            # print('Unique TFs:', self.num_tfs)\n",
        "\n",
        "        else:\n",
        "            self.motif_data = None\n",
        "\n",
        "        if type(expression_file) is str:\n",
        "            with Timer('Loading expression data ...'):\n",
        "                self.expression_data = pd.read_csv(expression_file, sep='\\t', header=None, index_col=0)\n",
        "                self.expression_genes = self.expression_data.index.tolist()\n",
        "                # self.num_genes = len(self.gene_names)\n",
        "                # print('Expression matrix:', self.expression_data.shape)\n",
        "        elif type(expression_file) is not str:\n",
        "            self.expression_data = expression_file #pd.read_csv(expression_file, sep='\\t', header=None, index_col=0)\n",
        "            self.expression_genes = self.expression_data.index.tolist()\n",
        "            # self.num_genes = len(self.gene_names)\n",
        "            # print('Expression matrix:', self.expression_data.shape)\n",
        "        else:\n",
        "            self.gene_names = list(set(self.motif_data[1]))\n",
        "            self.num_genes = len(self.gene_names)\n",
        "            self.expression_data = None #pd.DataFrame(np.identity(self.num_genes, dtype=int))\n",
        "            print('No Expression data given: correlation matrix will be an identity matrix of size', self.num_genes)\n",
        "\n",
        "        if type(ppi_file) is str:\n",
        "            with Timer('Loading PPI data ...'):\n",
        "                self.ppi_data = pd.read_csv(ppi_file, sep='\\t', header=None)\n",
        "                self.ppi_tfs  = sorted(set(self.ppi_data[0]))\n",
        "                print('Number of PPIs:', self.ppi_data.shape[0])\n",
        "        elif type(ppi_file) is not str:\n",
        "            self.ppi_data = ppi_file#pd.read_csv(ppi_file, sep='\\t', header=None)\n",
        "            self.ppi_tfs  = sorted(set(self.ppi_data[0]))\n",
        "            print('Number of PPIs:', self.ppi_data.shape[0])\n",
        "        else:\n",
        "            print('No PPI data given: ppi matrix will be an identity matrix of size', self.num_tfs)\n",
        "            self.ppi_data = None\n",
        "\n",
        "        if remove_missing and motif_file is not None:\n",
        "            self.__remove_missing()\n",
        "        \n",
        "        if modeProcess==\"legacy\":\n",
        "            self.gene_names = self.expression_genes#sorted( np.unique(self.motif_genes +  self.expression_genes ))\n",
        "            self.unique_tfs = self.motif_tfs#sorted( np.unique(self.ppi_tfs     +  self.motif_tfs ))\n",
        "\n",
        "        elif modeProcess==\"union\":\n",
        "            self.gene_names = sorted( np.unique(self.motif_genes +  self.expression_genes ))\n",
        "            self.unique_tfs = sorted( np.unique(self.ppi_tfs     +  self.motif_tfs ))\n",
        "\n",
        "        elif modeProcess==\"intersection\":\n",
        "            self.gene_names = sorted(np.unique( list(set(self.motif_genes).intersection(set(self.expression_genes))) ))\n",
        "            self.unique_tfs = sorted(np.unique( list(set(self.ppi_tfs).intersection(set(self.motif_tfs)) )))\n",
        "        \n",
        "        self.num_genes  = len(self.gene_names)\n",
        "        self.num_tfs    = len(self.unique_tfs)\n",
        "\n",
        "        # Auxiliary dicts\n",
        "        gene2idx = {x: i for i,x in enumerate(self.gene_names)}\n",
        "        tf2idx = {x: i for i,x in enumerate(self.unique_tfs)}\n",
        "        if modeProcess==\"union\":# or modeProcess==\"intersection\":\n",
        "            # Initialize data & Populate gene expression\n",
        "            self.expression = np.zeros((self.num_genes, self.expression_data.shape[1]))\n",
        "            print(self.expression.shape)\n",
        "            print(self.expression_data.shape)\n",
        "            # if modeProcess==\"union\":\n",
        "            idx_geneEx = [gene2idx.get(x, 0) for x in self.expression_genes]\n",
        "            # else:\n",
        "            #     idx_geneEx = [gene2idx.get(x, 0) for x in self.gene_names]\n",
        "            self.expression[idx_geneEx,:] = self.expression_data.values\n",
        "            self.expression_data=pd.DataFrame(data=self.expression)\n",
        "\n",
        "        # =====================================================================\n",
        "        # Network construction\n",
        "        # =====================================================================\n",
        "        with Timer('Calculating coexpression network ...'):\n",
        "            if self.expression_data is None:\n",
        "                self.correlation_matrix = np.identity(self.num_genes,dtype=int)\n",
        "            else:\n",
        "                self.correlation_matrix = np.corrcoef(self.expression_data)\n",
        "            if np.isnan(self.correlation_matrix).any():\n",
        "                np.fill_diagonal(self.correlation_matrix, 1)\n",
        "                self.correlation_matrix = np.nan_to_num(self.correlation_matrix)\n",
        "\n",
        "        # Clean up useless variables to release memory\n",
        "        if keep_expression_matrix:\n",
        "            self.expression_matrix = self.expression_data.values\n",
        "\n",
        "        if self.motif_data is None:\n",
        "            print('Returning the correlation matrix of expression data in <Panda_obj>.correlation_matrix')\n",
        "            self.panda_network        = self.correlation_matrix\n",
        "            self.export_panda_results = self.correlation_matrix\n",
        "            self.motif_matrix         = self.motif_data\n",
        "            self.ppi_matrix           = self.ppi_data\n",
        "            self.__pearson_results_data_frame()\n",
        "            return\n",
        "\n",
        "\n",
        "        with Timer('Creating motif network ...'):\n",
        "            self.motif_matrix_unnormalized = np.zeros((self.num_tfs, self.num_genes))\n",
        "            idx_tfs = [tf2idx.get(x, 0) for x in self.motif_data[0]]\n",
        "            idx_genes = [gene2idx.get(x, 0) for x in self.motif_data[1]]\n",
        "            idx = np.ravel_multi_index((idx_tfs, idx_genes), self.motif_matrix_unnormalized.shape)\n",
        "            self.motif_matrix_unnormalized.ravel()[idx] = self.motif_data[2]\n",
        "\n",
        "        if self.ppi_data is None:\n",
        "            self.ppi_matrix = np.identity(self.num_tfs,dtype=int)\n",
        "        else:\n",
        "            with Timer('Creating PPI network ...'):\n",
        "                self.ppi_matrix = np.identity(self.num_tfs)\n",
        "                idx_tf1 = [tf2idx.get(x, 0) for x in self.ppi_data[0]]\n",
        "                idx_tf2 = [tf2idx.get(x, 0) for x in self.ppi_data[1]]\n",
        "                idx = np.ravel_multi_index((idx_tf1, idx_tf2), self.ppi_matrix.shape)\n",
        "                self.ppi_matrix.ravel()[idx] = self.ppi_data[2]\n",
        "                idx = np.ravel_multi_index((idx_tf2, idx_tf1), self.ppi_matrix.shape)\n",
        "                self.ppi_matrix.ravel()[idx] = self.ppi_data[2]\n",
        "        \n",
        "        return\n",
        "\n",
        "    def panda_loop(self, correlation_matrix, motif_matrix, ppi_matrix,computing='cpu'):\n",
        "        \"\"\"Panda algorithm.\n",
        "        \"\"\"\n",
        "        def t_function(x, y=None):\n",
        "            '''T function.'''\n",
        "            if y is None:\n",
        "                a_matrix = np.dot(x, x.T)\n",
        "                s = np.square(x).sum(axis=1)\n",
        "                a_matrix /= np.sqrt(s + s.reshape(-1, 1) - np.abs(a_matrix))\n",
        "            else:\n",
        "                a_matrix = np.dot(x, y)\n",
        "                a_matrix /= np.sqrt(np.square(y).sum(axis=0) + np.square(x).sum(axis=1).reshape(-1, 1) - np.abs(a_matrix))\n",
        "            return a_matrix\n",
        "\n",
        "        def update_diagonal(diagonal_matrix, num, alpha, step):\n",
        "            '''Update diagonal.'''\n",
        "            np.fill_diagonal(diagonal_matrix, np.nan)\n",
        "            diagonal_std = np.nanstd(diagonal_matrix, 1)\n",
        "            diagonal_fill = diagonal_std * num * math.exp(2 * alpha * step)\n",
        "            np.fill_diagonal(diagonal_matrix, diagonal_fill)\n",
        "\n",
        "        def gt_function(x, y=None):\n",
        "            '''T function.'''\n",
        "            if y is None:\n",
        "                a_matrix = cp.dot(x, x.T)\n",
        "                s = cp.square(x).sum(axis=1)\n",
        "                a_matrix /= cp.sqrt(s + s.reshape(-1, 1) - cp.abs(a_matrix))\n",
        "            else:\n",
        "                a_matrix = cp.dot(x, y)\n",
        "                a_matrix /= cp.sqrt(cp.square(y).sum(axis=0) + cp.square(x).sum(axis=1).reshape(-1, 1) - cp.abs(a_matrix))\n",
        "            return a_matrix\n",
        "\n",
        "        def gupdate_diagonal(diagonal_matrix, num, alpha, step):\n",
        "            '''Update diagonal.'''\n",
        "            cp.fill_diagonal(diagonal_matrix, cp.nan)\n",
        "            diagonal_std = cp.nanstd(diagonal_matrix, 1)\n",
        "            diagonal_fill = diagonal_std * num * math.exp(2 * alpha * step)\n",
        "            cp.fill_diagonal(diagonal_matrix, diagonal_fill)\n",
        "\n",
        "        panda_loop_time = time.time()\n",
        "        num_tfs, num_genes = motif_matrix.shape\n",
        "        step = 0\n",
        "        hamming = 1\n",
        "        alpha = 0.1\n",
        "        \n",
        "        while hamming > 0.001:\n",
        "            # Update motif_matrix\n",
        "            if computing=='gpu':\n",
        "                import cupy as cp\n",
        "                ppi_matrix=cp.array(ppi_matrix)\n",
        "                motif_matrix=cp.array(motif_matrix)\n",
        "                correlation_matrix=cp.array(correlation_matrix)\n",
        "                W = 0.5 * (gt_function(ppi_matrix, motif_matrix) + gt_function(motif_matrix, correlation_matrix))  # W = (R + A) / 2\n",
        "                hamming = cp.abs(motif_matrix - W).mean()\n",
        "                motif_matrix=cp.array(motif_matrix)\n",
        "                motif_matrix *= (1 - alpha)\n",
        "                motif_matrix += (alpha * W)\n",
        "\n",
        "                if hamming > 0.001:\n",
        "                    # Update ppi_matrix\n",
        "                    ppi = gt_function(motif_matrix)  # t_func(X, X.T)\n",
        "                    gupdate_diagonal(ppi, num_tfs, alpha, step)\n",
        "                    ppi_matrix *= (1 - alpha)\n",
        "                    ppi_matrix += (alpha * ppi)\n",
        "\n",
        "                    # Update correlation_matrix\n",
        "                    motif = gt_function(motif_matrix.T)\n",
        "                    gupdate_diagonal(motif, num_genes, alpha, step)\n",
        "                    correlation_matrix *= (1 - alpha)\n",
        "                    correlation_matrix += (alpha * motif)\n",
        "\n",
        "                    del W, ppi, motif  # release memory for next step\n",
        "\n",
        "            elif computing=='cpu':\n",
        "                W = 0.5 * (t_function(ppi_matrix, motif_matrix) + t_function(motif_matrix, correlation_matrix))  # W = (R + A) / 2\n",
        "                hamming = np.abs(motif_matrix - W).mean()\n",
        "                motif_matrix *= (1 - alpha)\n",
        "                motif_matrix += (alpha * W)\n",
        "\n",
        "                if hamming > 0.001:\n",
        "                    # Update ppi_matrix\n",
        "                    ppi = t_function(motif_matrix)  # t_func(X, X.T)\n",
        "                    update_diagonal(ppi, num_tfs, alpha, step)\n",
        "                    ppi_matrix *= (1 - alpha)\n",
        "                    ppi_matrix += (alpha * ppi)\n",
        "                    \n",
        "                    # Update correlation_matrix\n",
        "                    motif = t_function(motif_matrix.T)\n",
        "                    update_diagonal(motif, num_genes, alpha, step)\n",
        "                    correlation_matrix *= (1 - alpha)\n",
        "                    correlation_matrix += (alpha * motif)\n",
        "\n",
        "                    del W, ppi, motif  # release memory for next step\n",
        "\n",
        "            print('step: {}, hamming: {}'.format(step, hamming))\n",
        "            step = step + 1\n",
        "\n",
        "        print('Running panda took: %.2f seconds!' % (time.time() - panda_loop_time))\n",
        "        #Ale: reintroducing the export_panda_results array if Panda called with save_memory=False\n",
        "        if computing=='gpu':\n",
        "            motif_matrix=cp.asnumpy(motif_matrix)\n",
        "        if hasattr(self,'unique_tfs'):\n",
        "            tfs = np.tile(self.unique_tfs, (len(self.gene_names), 1)).flatten()\n",
        "            genes = np.repeat(self.gene_names,self.num_tfs)\n",
        "            motif = self.motif_matrix_unnormalized.flatten(order='F')\n",
        "            force = motif_matrix.flatten(order='F')\n",
        "            self.export_panda_results = pd.DataFrame({'tf':tfs, 'gene': genes,'motif': motif, 'force': force})\n",
        "            #self.export_panda_results = np.column_stack((tfs,genes,motif,force))\n",
        "        return motif_matrix\n",
        "\n",
        "    def __pearson_results_data_frame(self):\n",
        "        '''Results to data frame.'''\n",
        "        genes_1 = np.tile(self.gene_names, (len(self.gene_names), 1)).flatten()\n",
        "        genes_2 = np.tile(self.gene_names, (len(self.gene_names), 1)).transpose().flatten()\n",
        "        self.flat_panda_network = self.panda_network.transpose().flatten()\n",
        "        self.export_panda_results = pd.DataFrame({'tf':genes_1, 'gene':genes_2, 'force':self.flat_panda_network})\n",
        "        self.export_panda_results = self.export_panda_results[['tf', 'gene', 'force']]\n",
        "        return None\n",
        "\n",
        "    def save_panda_results(self, path='panda.npy'):\n",
        "        with Timer('Saving PANDA network to %s ...' % path):\n",
        "            #Because there are two modes of operation (save_memory), save to file will be different\n",
        "            if hasattr(self,'panda_network'):\n",
        "                toexport = self.panda_network\n",
        "            else:\n",
        "                toexport = self.export_panda_results\n",
        "            #Export to file\n",
        "            if path.endswith('.txt'):\n",
        "                np.savetxt(path, toexport,fmt='%s', delimiter=' ')\n",
        "            elif path.endswith('.csv'):\n",
        "                np.savetxt(path, toexport,fmt='%s', delimiter=',')\n",
        "            elif path.endswith('.tsv'):\n",
        "                np.savetxt(path, toexport,fmt='%s', delimiter='/t')\n",
        "            else:\n",
        "                np.save(path, toexport)\n",
        "    def top_network_plot(self, top = 100, file = 'panda_top_100.png',plot_bipart=False):\n",
        "        '''Select top genes.'''\n",
        "        if not hasattr(self,'export_panda_results'):\n",
        "            raise AttributeError(\"Panda object does not contain the export_panda_results attribute.\\n\"+\n",
        "                \"Run Panda with the flag save_memory=False\")\n",
        "        #Ale TODO: work in numpy instead of pandas?\n",
        "        self.panda_results = pd.DataFrame(self.export_panda_results, columns=['tf','gene','motif','force'])\n",
        "        subset_panda_results = self.panda_results.sort_values(by=['force'], ascending=False)\n",
        "        subset_panda_results = subset_panda_results[subset_panda_results.tf != subset_panda_results.gene]\n",
        "        subset_panda_results = subset_panda_results[0:top]\n",
        "        self.__shape_plot_network(subset_panda_results = subset_panda_results, file = file, plot_bipart=plot_bipart)\n",
        "        return None\n",
        "    def __shape_plot_network(self, subset_panda_results, file = 'panda.png',plot_bipart=False):\n",
        "        '''Create plot.'''\n",
        "        #reshape data for networkx\n",
        "        unique_genes = list(set(list(subset_panda_results['tf'])+list(subset_panda_results['gene'])))\n",
        "        unique_genes = pd.DataFrame(unique_genes)\n",
        "        unique_genes.columns = ['name']\n",
        "        unique_genes['index'] = unique_genes.index\n",
        "        subset_panda_results = subset_panda_results.merge(unique_genes, how='inner', left_on='tf', right_on='name')\n",
        "        subset_panda_results = subset_panda_results.rename(columns = {'index': 'tf_index'})\n",
        "        subset_panda_results = subset_panda_results.drop(['name'], 1)\n",
        "        subset_panda_results = subset_panda_results.merge(unique_genes, how='inner', left_on='gene', right_on='name')\n",
        "        subset_panda_results = subset_panda_results.rename(columns = {'index': 'gene_index'})\n",
        "        subset_panda_results = subset_panda_results.drop(['name'], 1)\n",
        "        links = subset_panda_results[['tf_index', 'gene_index', 'force']]\n",
        "        self.__create_plot(unique_genes = unique_genes, links = links, file = file,plot_bipart=plot_bipart)\n",
        "        return None\n",
        "    def __create_plot(self, unique_genes, links, file = 'panda.png',plot_bipart=False):\n",
        "        '''Run plot.'''\n",
        "        import networkx as nx\n",
        "        import matplotlib.pyplot as plt\n",
        "        g = nx.Graph()\n",
        "        g.clear()\n",
        "        plt.clf()\n",
        "        #img = plt.imread(\"../img/panda.jpg\")\n",
        "        #fig, ax = plt.subplots()\n",
        "        #ax.imshow(img, extent=[0, 400, 0, 300])\n",
        "        ##ax.plot(x, x, '--', linewidth=5, color='firebrick')\n",
        "        g.add_nodes_from(unique_genes['index'])\n",
        "        edges = []\n",
        "        for i in range(0, len(links)):\n",
        "            edges = edges + [(links.iloc[i]['tf_index'], links.iloc[i]['gene_index'], float(links.iloc[i]['force'])/200)]\n",
        "        g.add_weighted_edges_from(edges)\n",
        "        labels = {}\n",
        "        def split_label(label):\n",
        "            ll = len(label)\n",
        "            if ll > 6:\n",
        "                return label[0:int(np.ceil(ll/2))] + '\\n' + label[int(np.ceil(ll/2)):]\n",
        "            return label\n",
        "        for i, l in enumerate(unique_genes.iloc[:,0]):\n",
        "            labels[i] = split_label(l)\n",
        "        if not plot_bipart:\n",
        "            pos = nx.spring_layout(g)\n",
        "        else:\n",
        "            pos = nx.drawing.layout.bipartite_layout(g, set(links['tf_index']))\n",
        "        #nx.draw_networkx(g, pos, labels=labels, node_size=40, font_size=3, alpha=0.3, linewidth = 0.5, width =0.5)\n",
        "        print(plot_bipart)\n",
        "        if not plot_bipart:\n",
        "            colors=range(len(edges))\n",
        "        else:\n",
        "            colors=list(zip(*edges))[-1]\n",
        "                                                     \n",
        "        options = {'alpha': 0.7, 'edge_color': colors, 'edge_cmap': plt.cm.Blues, 'node_size' :110, 'vmin': -100,\n",
        "                   'width': 2, 'labels': labels, 'font_weight': 'regular', 'font_size': 3, 'linewidth': 20}\n",
        "        \n",
        "        nx.draw_networkx(g, k=0.25, iterations=50, pos=pos,**options)\n",
        "        plt.axis('off')\n",
        "        plt.savefig(file, dpi=300)\n",
        "        return None\n",
        "\n",
        "    def return_panda_indegree(self):\n",
        "        '''Return Panda indegree.'''\n",
        "        export_panda_results_pd = pd.DataFrame(self.export_panda_results,columns=['tf','gene','motif','force'])\n",
        "        subset_indegree = export_panda_results_pd.loc[:,['gene','force']]\n",
        "        self.panda_indegree = subset_indegree.groupby('gene').sum()\n",
        "        return self.panda_indegree\n",
        "    def return_panda_outdegree(self):\n",
        "        '''Return Panda outdegree.'''\n",
        "        export_panda_results_pd = pd.DataFrame(self.export_panda_results,columns=['tf','gene','motif','force'])\n",
        "        subset_outdegree = export_panda_results_pd.loc[:,['tf','force']]\n",
        "        self.panda_outdegree = subset_outdegree.groupby('tf').sum()\n",
        "        return self.panda_outdegree\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCNPVw_zBr_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d04211f2-6bdf-42b3-d9fe-44961fc26654"
      },
      "source": [
        "panda_obj3=Panda3('netZooPy/tests/puma/ToyData/ToyExpressionData.txt',\n",
        "                'netZooPy/tests/puma/ToyData/ToyMotifData.txt',\n",
        "                'netZooPy/tests/puma/ToyData/ToyPPIData.txt',\n",
        "    computing='cpu',precision='double',save_memory = False, save_tmp=False, \n",
        "    remove_missing= True, keep_expression_matrix = False,\n",
        "     modeProcess = 'intersection')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading motif data ...\n",
            "  Elapsed time: 0.02 sec.\n",
            "Loading expression data ...\n",
            "  Elapsed time: 0.02 sec.\n",
            "Loading PPI data ...\n",
            "Number of PPIs: 238\n",
            "  Elapsed time: 0.00 sec.\n",
            "Remove expression not in motif:\n",
            "   87 rows removed from the initial 1000\n",
            "Remove motif not in expression data:\n",
            "   0 rows removed from the initial 14597\n",
            "Remove ppi not in motif:\n",
            "   0 rows removed from the initial 238\n",
            "Calculating coexpression network ...\n",
            "  Elapsed time: 0.02 sec.\n",
            "Creating motif network ...\n",
            "  Elapsed time: 0.02 sec.\n",
            "Creating PPI network ...\n",
            "  Elapsed time: 0.00 sec.\n",
            "Normalizing networks ...\n",
            "  Elapsed time: 0.05 sec.\n",
            "Running PANDA algorithm ...\n",
            "step: 0, hamming: 0.7798917226715182\n",
            "step: 1, hamming: 0.451137928345031\n",
            "step: 2, hamming: 0.518685514316148\n",
            "step: 3, hamming: 0.555300393166025\n",
            "step: 4, hamming: 0.5728475146737425\n",
            "step: 5, hamming: 0.5766241758460399\n",
            "step: 6, hamming: 0.5689601133089167\n",
            "step: 7, hamming: 0.5515789177300446\n",
            "step: 8, hamming: 0.5262246706690599\n",
            "step: 9, hamming: 0.4947831876631561\n",
            "step: 10, hamming: 0.4590910225472031\n",
            "step: 11, hamming: 0.4208788960432843\n",
            "step: 12, hamming: 0.38166815748959326\n",
            "step: 13, hamming: 0.3427177973625151\n",
            "step: 14, hamming: 0.3050160548238351\n",
            "step: 15, hamming: 0.2692890750501229\n",
            "step: 16, hamming: 0.23602872335494865\n",
            "step: 17, hamming: 0.2055261731557181\n",
            "step: 18, hamming: 0.1779104786846009\n",
            "step: 19, hamming: 0.1531853925472216\n",
            "step: 20, hamming: 0.13126216807246605\n",
            "step: 21, hamming: 0.11198784327672719\n",
            "step: 22, hamming: 0.09516868953648845\n",
            "step: 23, hamming: 0.08058872386166728\n",
            "step: 24, hamming: 0.0680236694822223\n",
            "step: 25, hamming: 0.05725129701349013\n",
            "step: 26, hamming: 0.04805856895803555\n",
            "step: 27, hamming: 0.04024625373875233\n",
            "step: 28, hamming: 0.03363159225178915\n",
            "step: 29, hamming: 0.028049512993310672\n",
            "step: 30, hamming: 0.023352809808047728\n",
            "step: 31, hamming: 0.019411588728599747\n",
            "step: 32, hamming: 0.016112260645006263\n",
            "step: 33, hamming: 0.01335624551538499\n",
            "step: 34, hamming: 0.011058551988398724\n",
            "step: 35, hamming: 0.009146322182726688\n",
            "step: 36, hamming: 0.007557409912691692\n",
            "step: 37, hamming: 0.006239034872915108\n",
            "step: 38, hamming: 0.0051465454879328285\n",
            "step: 39, hamming: 0.004242294882640481\n",
            "step: 40, hamming: 0.003494637629986916\n",
            "step: 41, hamming: 0.002877044453465468\n",
            "step: 42, hamming: 0.0023673283351637727\n",
            "step: 43, hamming: 0.0019469734531065543\n",
            "step: 44, hamming: 0.0016005572951987828\n",
            "step: 45, hamming: 0.0013152558890787331\n",
            "step: 46, hamming: 0.001080422443647737\n",
            "step: 47, hamming: 0.0008872299366588617\n",
            "Running panda took: 2.15 seconds!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Att58XwBBtYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d166a53f-aeac-4cc1-c9cd-d139b41ae575"
      },
      "source": [
        "panda_obj3.panda_network.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74, 913)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl8iMMHSBzms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef4f03e5-820f-4f25-f3ab-1ccdd2201cae"
      },
      "source": [
        "sum(sum(panda_obj3.panda_network==panda_obj.panda_network))/(74*913)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.751013883544004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wrIYXaJB2cK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}